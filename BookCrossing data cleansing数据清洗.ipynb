{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim \n",
    "import tqdm   #to visualize loops' progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare the path variables\n",
    "root_path = os.getcwd()\n",
    "data_dir = os.path.join(root_path,'Data','datasets')\n",
    "new_data_dir = os.path.join(root_path,'Data','datasets','new datasets')\n",
    "if not os.path.isdir(new_data_dir):\n",
    "    os.mkdir(new_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data from csv\n",
    "# read Users\n",
    "u_cols = ['user_id', 'location', 'age']\n",
    "users = pd.read_csv(os.path.join(data_dir,'BX_Users.csv'), sep=';', names=u_cols, encoding='latin-1',low_memory=False)\n",
    "\n",
    "# read Books/items\n",
    "i_cols = ['isbn', 'book_title' ,'book_author','year_of_publication', 'publisher', 'img_s', 'img_m', 'img_l']\n",
    "items = pd.read_csv(os.path.join(data_dir,'BX_Books.csv'), sep=';', names=i_cols, encoding='latin-1',low_memory=False)\n",
    "\n",
    "# read Ratings\n",
    "r_cols = ['user_id', 'isbn', 'rating']\n",
    "ratings = pd.read_csv(os.path.join(data_dir,'BX_Book_Ratings.csv'), sep=';', names=r_cols, encoding='latin-1',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________Users__________________________________\n",
      "   user_id                   location  age\n",
      "0  User-ID                   Location  Age\n",
      "1        1         nyc, new york, usa  NaN\n",
      "2        2  stockton, california, usa   18\n",
      "\n",
      "\n",
      "__________________________________Items__________________________________\n",
      "         isbn           book_title           book_author  year_of_publication  \\\n",
      "0        ISBN           Book-Title           Book-Author  Year-Of-Publication   \n",
      "1  0195153448  Classical Mythology    Mark P. O. Morford                 2002   \n",
      "2  0002005018         Clara Callan  Richard Bruce Wright                 2001   \n",
      "\n",
      "                 publisher                                              img_s  \\\n",
      "0                Publisher                                        Image-URL-S   \n",
      "1  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n",
      "2    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
      "\n",
      "                                               img_m  \\\n",
      "0                                        Image-URL-M   \n",
      "1  http://images.amazon.com/images/P/0195153448.0...   \n",
      "2  http://images.amazon.com/images/P/0002005018.0...   \n",
      "\n",
      "                                               img_l  \n",
      "0                                        Image-URL-L  \n",
      "1  http://images.amazon.com/images/P/0195153448.0...  \n",
      "2  http://images.amazon.com/images/P/0002005018.0...  \n",
      "\n",
      "\n",
      "_________________________________Ratings_________________________________\n",
      "   user_id        isbn       rating\n",
      "0  User-ID        ISBN  Book-Rating\n",
      "1   276725  034545104X            0\n",
      "2   276726  0155061224            5\n"
     ]
    }
   ],
   "source": [
    "print('__________________________________Users__________________________________')\n",
    "print(users.head(3))\n",
    "print(\"\\n\")\n",
    "print('__________________________________Items__________________________________')\n",
    "print(items.head(3))\n",
    "print(\"\\n\")\n",
    "print('_________________________________Ratings_________________________________')\n",
    "print(ratings.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p><p style=\"font-size:15pt\">删除不需要的列</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________Users__________________________________\n",
      "  user_id                            location  age\n",
      "0       1                  nyc, new york, usa  NaN\n",
      "1       2           stockton, california, usa   18\n",
      "2       3     moscow, yukon territory, russia  NaN\n",
      "3       4           porto, v.n.gaia, portugal   17\n",
      "4       5  farnborough, hants, united kingdom  NaN\n",
      "\n",
      "\n",
      "__________________________________Items__________________________________\n",
      "         isbn                                         book_title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "            book_author year_of_publication                   publisher  \\\n",
      "0    Mark P. O. Morford                2002     Oxford University Press   \n",
      "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
      "2          Carlo D'Este                1991             HarperPerennial   \n",
      "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
      "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
      "\n",
      "                                               img_m  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n",
      "3  http://images.amazon.com/images/P/0374157065.0...  \n",
      "4  http://images.amazon.com/images/P/0393045218.0...  \n",
      "\n",
      "\n",
      "_________________________________Ratings_________________________________\n",
      "  user_id        isbn rating\n",
      "0  276725  034545104X      0\n",
      "1  276726  0155061224      5\n",
      "2  276727  0446520802      0\n",
      "3  276729  052165615X      3\n",
      "4  276729  0521795028      6\n"
     ]
    }
   ],
   "source": [
    "users = users.loc[1:]\n",
    "users.reset_index(drop=True, inplace=True)\n",
    "\n",
    "items = items.loc[1:]\n",
    "items.reset_index(drop=True, inplace=True)\n",
    "items.drop(['img_s','img_l'], axis=1, inplace=True)\n",
    "\n",
    "ratings = ratings.loc[1:]\n",
    "ratings.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('__________________________________Users__________________________________')\n",
    "print(users.head(5))\n",
    "print(\"\\n\")\n",
    "print('__________________________________Items__________________________________')\n",
    "print(items.head(5))\n",
    "print(\"\\n\")\n",
    "print('_________________________________Ratings_________________________________')\n",
    "print(ratings.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p><p style=\"font-size:15pt\">查看数据</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id                         location     age\n",
      "count   278858                           278858  168096\n",
      "unique  278858                            57339     165\n",
      "top     104278  london, england, united kingdom      24\n",
      "freq         1                             2506    5687 \n",
      "\n",
      "\n",
      "              isbn      book_title      book_author year_of_publication  \\\n",
      "count       271379          271379           271378              271379   \n",
      "unique      271379          242154           102042                 137   \n",
      "top     0895772256  Selected Poems  Agatha Christie                2002   \n",
      "freq             1              27              632               17627   \n",
      "\n",
      "        publisher                                              img_m  \n",
      "count      271377                                             271379  \n",
      "unique      16824                                             271063  \n",
      "top     Harlequin  http://images.amazon.com/images/P/043935806X.0...  \n",
      "freq         7535                                                  2   \n",
      "\n",
      "\n",
      "        user_id        isbn   rating\n",
      "count   1149780     1149780  1149780\n",
      "unique   105283      340556       11\n",
      "top       11676  0971880107        0\n",
      "freq      13602        2502   716109\n"
     ]
    }
   ],
   "source": [
    "print(users.describe(),\"\\n\"*2)\n",
    "print(items.describe(),\"\\n\"*2)\n",
    "print(ratings.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>278858.00000</td>\n",
       "      <td>278858</td>\n",
       "      <td>168096.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>57339</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>london, england, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2506</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>139429.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.751434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>80499.51502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.428097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>69715.25000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>139429.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>209143.75000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>278858.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                         location            age\n",
       "count   278858.00000                           278858  168096.000000\n",
       "unique           NaN                            57339            NaN\n",
       "top              NaN  london, england, united kingdom            NaN\n",
       "freq             NaN                             2506            NaN\n",
       "mean    139429.50000                              NaN      34.751434\n",
       "std      80499.51502                              NaN      14.428097\n",
       "min          1.00000                              NaN       0.000000\n",
       "25%      69715.25000                              NaN      24.000000\n",
       "50%     139429.50000                              NaN      32.000000\n",
       "75%     209143.75000                              NaN      44.000000\n",
       "max     278858.00000                              NaN     244.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.age = users.age.astype(float)\n",
    "users.user_id = users.user_id.astype(int)\n",
    "users.describe(include=[object, int, float])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br><h2 style=\"font-size:20pt;\"> users.age</h2>\n",
    "\n",
    "<p style=\"font-size:15pt\"> Let's take a closer look at \"users.age\" Series. As we can see from above it has a mean value around 34.75 and a deviation of 14.43. Next, we shall investigate how many NaN values there are in the Series and how many values are \"not so logical\" (> 5 or < 99).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in age: 0\n",
      "Users with 5 > age & age > 99 : 1255\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values in age:\", users.age[users.age.isna()].count())\n",
    "print(\"Users with 5 > age & age > 99 :\",users.loc[(users.age>99) | (users.age<5),'age'].count())\n",
    "users.loc[(users.age>99) | (users.age<5),'age'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15pt\"><b>Wow</b>, 110762 missing values in <em>users.age</em> and another 1255 users have <i>age</i> values that I think are invalid. <br></br>Since we really don't like NaN values in datasets we will replace them with a value. This value can be the mean age of the users that registered their age or it can be based on some values of the dataset. For example, we can use the location of the user and use the average age of the population of this location, or we can use the average age of the population using PCs on that location since this dataset was collected from a website. We can even use an ML algorithm to determine the missing values. The easiest way  would be to use the mean.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    278858.000000\n",
       "mean         34.743900\n",
       "std          10.540292\n",
       "min           5.000000\n",
       "25%          29.000000\n",
       "50%          34.743900\n",
       "75%          35.000000\n",
       "max          99.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.age.fillna(users.age.mean()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of values in 'users.age'\n",
      " count    166841.000000\n",
      "mean         34.743900\n",
      "std          13.626783\n",
      "min           5.000000\n",
      "25%          24.000000\n",
      "50%          32.000000\n",
      "75%          44.000000\n",
      "max          99.000000\n",
      "Name: age, dtype: float64 \n",
      "\n",
      "Statistics of values we are going to use to fill NaN \n",
      " count    112017.000000\n",
      "mean         34.727375\n",
      "std          13.645074\n",
      "min         -26.551841\n",
      "25%          25.551266\n",
      "50%          34.738286\n",
      "75%          43.941889\n",
      "max          96.612554\n",
      "dtype: float64 \n",
      "\n",
      "Negative values in 'temp_age_seires': 608 \n",
      "\n",
      "As we can see the destribution doesnt change a lot. There are some negative values thought (around 600 of them).\n",
      "\n",
      "count    278858.000000\n",
      "mean         34.921591\n",
      "std          13.390613\n",
      "min           5.000000\n",
      "25%          25.000000\n",
      "50%          33.000000\n",
      "75%          44.000000\n",
      "max          99.000000\n",
      "Name: age, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                            location  age\n",
       "0        1                  nyc, new york, usa   24\n",
       "1        2           stockton, california, usa   18\n",
       "2        3     moscow, yukon territory, russia   24\n",
       "3        4           porto, v.n.gaia, portugal   17\n",
       "4        5  farnborough, hants, united kingdom   63"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a normal disgtribution pd.Series to fill Nan values with\n",
    "temp_age_series = pd.Series(np.random.normal(loc=users.age.mean(), scale=users.age.std(), size=users.user_id[users.age.isna()].count()))\n",
    "print(\"Statistics of values in \\'users.age\\'\\n\",users.age.describe(),\"\\n\")\n",
    "print(\"Statistics of values we are going to use to fill NaN \\n\",temp_age_series.describe(),\"\\n\")\n",
    "print(\"Negative values in \\'temp_age_seires\\':\", temp_age_series[temp_age_series<0].count(),\"\\n\")\n",
    "print(\"As we can see the destribution doesnt change a lot. There are some negative values thought (around 600 of them).\\n\")\n",
    "\n",
    "# take the abs value of temp_age_series\n",
    "pos_age_series=np.abs(temp_age_series)\n",
    "\n",
    "# sort users Df so as NaN values in age to be first and reset index to match with index of pos_age_series. Then use fillna()\n",
    "users = users.sort_values('age',na_position='first').reset_index(drop=True)\n",
    "users.age.fillna(pos_age_series, inplace = True)  \n",
    "\n",
    "# replace values < 5 with the mean(). Round values and convert them to int. \n",
    "users.loc[users.age<5, 'age'] = users.age.mean()\n",
    "users.age = users.age.round().astype(int)\n",
    "#Sort users based on user_id so as to be the same as before\n",
    "users = users.sort_values('user_id').reset_index(drop=True)\n",
    "print(users.age.describe(),\"\\n\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    nyc, new york, usa\n",
       "1             stockton, california, usa\n",
       "2       moscow, yukon territory, russia\n",
       "3             porto, v.n.gaia, portugal\n",
       "4    farnborough, hants, united kingdom\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>278858</td>\n",
       "      <td>278857</td>\n",
       "      <td>274281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>33076</td>\n",
       "      <td>6663</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>london</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4105</td>\n",
       "      <td>19839</td>\n",
       "      <td>139421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city       state country\n",
       "count   278858      278857  274281\n",
       "unique   33076        6663    1130\n",
       "top     london  california     usa\n",
       "freq      4105       19839  139421"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_split=users.location.str.split(', ', n=2, expand=True)\n",
    "location_split.columns=['city', 'state', 'country']\n",
    "location_split.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_split.loc[location_split.state==',', ['state', 'country']] = 'other'\n",
    "location_split.loc[location_split.country==',', ['country']] = 'other'\n",
    "location_split.loc[(location_split.state=='\\\\n/a\\\\\"') | (location_split.state=='') | (location_split.state=='*') | (location_split.state=='n.a'), ['state']] = 'n/a'\n",
    "location_split.state.fillna('other', inplace=True)\n",
    "location_split.fillna('n/a', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_location_df = pd.concat([location_split.city, location_split.state,  location_split.country, location_split.state, location_split.city, location_split.country, location_split.city], axis=1)\n",
    "location_list = temp_location_df.fillna('n/a').values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK is to Milton Keynes what Greece is to : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('crete', 0.9693020582199097),\n",
       " ('piraeus', 0.9634312987327576),\n",
       " ('attiki', 0.9616715908050537),\n",
       " ('papagou', 0.9522576332092285),\n",
       " ('attika', 0.9521435499191284),\n",
       " ('maroussi', 0.95106041431427),\n",
       " ('thessaloniki', 0.9464523792266846),\n",
       " ('basilika', 0.943909764289856),\n",
       " ('attica', 0.940754234790802),\n",
       " ('patras', 0.940321683883667),\n",
       " ('arequipa', 0.9388856291770935),\n",
       " ('denizli', 0.9370570182800293),\n",
       " ('chery hill', 0.9368599653244019),\n",
       " ('drama', 0.9359506368637085),\n",
       " ('serres', 0.934550404548645),\n",
       " ('magnisia', 0.933468759059906),\n",
       " ('trujillo', 0.9325399398803711),\n",
       " ('lavrio', 0.932529091835022),\n",
       " ('aten', 0.930486798286438),\n",
       " ('athens', 0.9298406839370728)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "model = gensim.models.Word2Vec(location_list, size= n, window=3, min_count=1, workers=4)\n",
    "print ('UK is to Milton Keynes what Greece is to : ')\n",
    "model.wv.most_similar(positive=['greece','united kingdom'], negative=['milton keynes'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose '1' to skip this step or '2' to construct the 'location_vec' DataFrame.1\n",
      "Skipping operations\n"
     ]
    }
   ],
   "source": [
    "rightchoice=['1','2']\n",
    "choice = input(\"Choose \\'1\\' to skip this step or \\'2\\' to construct the \\'location_vec\\' DataFrame.\")\n",
    "while choice not in rightchoice:\n",
    "    choice = input(\"Wrong input. \\n Insert a number. Either 1 or 2\")\n",
    "if choice=='1':\n",
    "    print ('Skipping operations')\n",
    "else:\n",
    "    zipp = list(zip(model.wv.index2word, model.wv.syn0))\n",
    "    vectors = np.zeros((location_split.shape[0],3*n))\n",
    "    for i in tqdm.tqdm_notebook(range(location_split.shape[0])):\n",
    "        vectors[i, 0:20] = [j[1][0] for j in zipp if j[0] == location_split.loc[i, 'city']]\n",
    "        vectors[i,20:40] = [j[1][0] for j in zipp if j[0] == location_split.loc[i, 'state']]\n",
    "        vectors[i,40:60] = [j[1][0] for j in zipp if j[0] == location_split.loc[i, 'country']]\n",
    "    col=[]\n",
    "    for i in range(20):\n",
    "        col.append('city_'+ str(i))\n",
    "    for i in range(20):\n",
    "        col.append('state_'+ str(i))\n",
    "    for i in range(20):\n",
    "        col.append('country_'+ str(i))\n",
    "\n",
    "    location_vec = pd.DataFrame(vectors, columns = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc</td>\n",
       "      <td>new york</td>\n",
       "      <td>usa</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton</td>\n",
       "      <td>california</td>\n",
       "      <td>usa</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow</td>\n",
       "      <td>yukon territory</td>\n",
       "      <td>russia</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto</td>\n",
       "      <td>v.n.gaia</td>\n",
       "      <td>portugal</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough</td>\n",
       "      <td>hants</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id         city            state         country  age\n",
       "0        1          nyc         new york             usa   24\n",
       "1        2     stockton       california             usa   18\n",
       "2        3       moscow  yukon territory          russia   24\n",
       "3        4        porto         v.n.gaia        portugal   17\n",
       "4        5  farnborough            hants  united kingdom   63"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'location_vec' in globals():\n",
    "    users_new = pd.concat([users.user_id, location_vec , users.age], axis=1)    \n",
    "else:\n",
    "    users_new = pd.concat([users.user_id, location_split , users.age], axis=1)\n",
    "users_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105283 users have submited at least one review\n",
      "173575 users have not submited any review\n"
     ]
    }
   ],
   "source": [
    "print(users_new[users_new.user_id.isin(ratings.user_id)].user_id.count(),'users have submited at least one review')\n",
    "print(users_new[~users_new.user_id.isin(ratings.user_id)].user_id.count(), 'users have not submited any review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn                                         book_title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            book_author  year_of_publication                publisher  \\\n",
       "0    Mark P. O. Morford                 2002  Oxford University Press   \n",
       "1  Richard Bruce Wright                 2001    HarperFlamingo Canada   \n",
       "2          Carlo D'Este                 1991          HarperPerennial   \n",
       "3      Gina Bari Kolata                 1999     Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                 1999   W. W. Norton & Company   \n",
       "\n",
       "                                               img_m  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv(os.path.join(data_dir,'BX_Books_correct.csv'), sep=';', names=i_cols, encoding='latin-1',low_memory=False)\n",
    "items = items.loc[1:]\n",
    "items.reset_index(drop=True, inplace=True)\n",
    "items.drop(['img_s','img_l'], axis=1, inplace=True)\n",
    "items.year_of_publication = items.year_of_publication.astype(int)\n",
    "items.describe(include =[object, int])\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items with NaN values in \"book_author\": \n",
      " 187700    9627982032\n",
      "Name: isbn, dtype: object \n",
      "\n",
      "Items values in \"publisher\": \n",
      " 128896    193169656X\n",
      "129043    1931696993\n",
      "Name: isbn, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (\"Items with NaN values in \\\"book_author\\\": \\n\", items.isbn[items.book_author.isna()],\"\\n\")\n",
    "print (\"Items values in \\\"publisher\\\": \\n\", items.isbn[items.publisher.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.loc[187701,'book_author'] = \"n/a\"\n",
    "items.loc[[128897, 129044],'publisher'] = \"NovelBooks, Inc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items with (year_of_publication > 2010): 20 \n",
      "\n",
      "value_counts of items with (year_of_publication < 1500): \n",
      " 0       4619\n",
      "1378       1\n",
      "1376       1\n",
      "Name: year_of_publication, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Items with (year_of_publication > 2010):', items.year_of_publication[items.year_of_publication>2010].count(),'\\n')\n",
    "print('value_counts of items with (year_of_publication < 1500): \\n', items.year_of_publication[items.year_of_publication<1500].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year_of_publication\n",
      "count        266740.000000\n",
      "mean           1993.687062\n",
      "std               8.320673\n",
      "min            1376.000000\n",
      "25%            1989.000000\n",
      "50%            1996.000000\n",
      "75%            2000.000000\n",
      "max            2010.000000 \n",
      "\n",
      "count    271379.000000\n",
      "mean       1993.692412\n",
      "std           8.249348\n",
      "min        1376.000000\n",
      "25%        1989.000000\n",
      "50%        1995.000000\n",
      "75%        2000.000000\n",
      "max        2010.000000\n",
      "Name: year_of_publication, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "items.loc[(items.year_of_publication>2010)|(items.year_of_publication<1000),'year_of_publication'] = np.nan\n",
    "print(items.describe(),'\\n')\n",
    "print(items.year_of_publication.fillna(round(items.year_of_publication.mean())).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.year_of_publication.fillna(round(items.year_of_publication.mean()),inplace=True)\n",
    "items.year_of_publication = items.year_of_publication.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              isbn    book_title      book_author         publisher  \\\n",
      "count        35921         35921            35921             35921   \n",
      "unique       35921         15376             7694              2505   \n",
      "top     0446612588  Little Women  Agatha Christie  Ballantine Books   \n",
      "freq             1            21              259              1095   \n",
      "\n",
      "                                                    img_m  \n",
      "count                                               35921  \n",
      "unique                                              35606  \n",
      "top     http://images.amazon.com/images/P/067103619X.0...  \n",
      "freq                                                    2  \n",
      "              isbn    book_title   book_author         publisher  \\\n",
      "count        20175         20175         20175             20175   \n",
      "unique       20175         15376          7694              2019   \n",
      "top     0441385516  Little Women  Stephen King  Ballantine Books   \n",
      "freq             1            20           192               590   \n",
      "\n",
      "                                                    img_m  \n",
      "count                                               20175  \n",
      "unique                                              20132  \n",
      "top     http://images.amazon.com/images/P/014029855X.0...  \n",
      "freq                                                    2  \n",
      "Stephen King           192\n",
      "Agatha Christie        156\n",
      "Dick Francis            90\n",
      "Jane Austen             72\n",
      "William Shakespeare     71\n",
      "Name: book_author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(items[(items.duplicated(['book_title', 'book_author'], keep=False))].describe(include=[object]))\n",
    "print(items[(items.duplicated(['book_title', 'book_author'], keep='first'))].describe(include=[object]))\n",
    "print(items[(items.duplicated(['book_title', 'book_author']))].book_author.value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>251204</td>\n",
       "      <td>251204</td>\n",
       "      <td>251203</td>\n",
       "      <td>251204.000000</td>\n",
       "      <td>251202</td>\n",
       "      <td>251204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>251204</td>\n",
       "      <td>242154</td>\n",
       "      <td>102029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16617</td>\n",
       "      <td>251203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0895772256</td>\n",
       "      <td>Selected Poems</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harlequin</td>\n",
       "      <td>http://images.amazon.com/images/P/051513628X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7508</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.705817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.245138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1376.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              isbn      book_title          book_author  year_of_publication  \\\n",
       "count       251204          251204               251203        251204.000000   \n",
       "unique      251204          242154               102029                  NaN   \n",
       "top     0895772256  Selected Poems  William Shakespeare                  NaN   \n",
       "freq             1              25                  496                  NaN   \n",
       "mean           NaN             NaN                  NaN          1993.705817   \n",
       "std            NaN             NaN                  NaN             8.245138   \n",
       "min            NaN             NaN                  NaN          1376.000000   \n",
       "25%            NaN             NaN                  NaN          1989.000000   \n",
       "50%            NaN             NaN                  NaN          1995.000000   \n",
       "75%            NaN             NaN                  NaN          2000.000000   \n",
       "max            NaN             NaN                  NaN          2008.000000   \n",
       "\n",
       "        publisher                                              img_m  \n",
       "count      251202                                             251204  \n",
       "unique      16617                                             251203  \n",
       "top     Harlequin  http://images.amazon.com/images/P/051513628X.0...  \n",
       "freq         7508                                                  2  \n",
       "mean          NaN                                                NaN  \n",
       "std           NaN                                                NaN  \n",
       "min           NaN                                                NaN  \n",
       "25%           NaN                                                NaN  \n",
       "50%           NaN                                                NaN  \n",
       "75%           NaN                                                NaN  \n",
       "max           NaN                                                NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_wo_duplicates = items.drop_duplicates(['book_title', 'book_author'])\n",
    "items_wo_duplicates.describe(include=[object,int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1031175</td>\n",
       "      <td>1031175</td>\n",
       "      <td>1031175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>92107</td>\n",
       "      <td>270170</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>11676</td>\n",
       "      <td>0971880107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11144</td>\n",
       "      <td>2502</td>\n",
       "      <td>647323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        isbn   rating\n",
       "count   1031175     1031175  1031175\n",
       "unique    92107      270170       11\n",
       "top       11676  0971880107        0\n",
       "freq      11144        2502   647323"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_new = ratings[ratings.isbn.isin(items.isbn)]\n",
    "ratings_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     647323\n",
      "1       1481\n",
      "2       2375\n",
      "3       5118\n",
      "4       7617\n",
      "5      45355\n",
      "6      31689\n",
      "7      66404\n",
      "8      91806\n",
      "9      60780\n",
      "10     71227\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1031175</td>\n",
       "      <td>1031175</td>\n",
       "      <td>1.031175e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>92107</td>\n",
       "      <td>270170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>11676</td>\n",
       "      <td>0971880107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11144</td>\n",
       "      <td>2502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.839022e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.854149e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        isbn        rating\n",
       "count   1031175     1031175  1.031175e+06\n",
       "unique    92107      270170           NaN\n",
       "top       11676  0971880107           NaN\n",
       "freq      11144        2502           NaN\n",
       "mean        NaN         NaN  2.839022e+00\n",
       "std         NaN         NaN  3.854149e+00\n",
       "min         NaN         NaN  0.000000e+00\n",
       "25%         NaN         NaN  0.000000e+00\n",
       "50%         NaN         NaN  0.000000e+00\n",
       "75%         NaN         NaN  7.000000e+00\n",
       "max         NaN         NaN  1.000000e+01"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_new.loc[:,'rating'] = ratings_new.rating.astype(int)\n",
    "print(ratings_new.rating.value_counts(sort=False))\n",
    "ratings_new.describe(include=[object,int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose '1' to import the ratings_wo_duplicates file or '2' to construct it again 1\n",
      "Importing 'ratings_wo_duplicates.csv'\n",
      "Done\n",
      "\n",
      "And to make sure that the procedure was carried out smoothly,\n",
      "No of duplicates in \"ratings_wo_duplicates\" : 0\n"
     ]
    }
   ],
   "source": [
    "choice = input(\"Choose \\'1\\' to import the ratings_wo_duplicates file or \\'2\\' to construct it again \")\n",
    "while choice not in rightchoice:\n",
    "    choice = input(\"Wrong input. \\n Insert a number. Either 1 or 2\")\n",
    "\n",
    "if choice == '1':\n",
    "    print('Importing \\'ratings_wo_duplicates.csv\\'')\n",
    "    ratings_wo_duplicates=pd.read_csv(os.path.join(data_dir,'ratings_wo_duplicates.csv'), sep=';', names=r_cols, encoding='latin-1', low_memory=False )\n",
    "    print('Done')\n",
    "elif choice == '2':\n",
    "    print('Constructing \\'ratings_wo_duplicates.csv\\'')\n",
    "    print('Please remember the number of processed and stored items incase the operation is interupted and you would like continue from there.')\n",
    "    \n",
    "    choice = input(\"Choose \\'1\\' to iterate through all items or \\'2\\' if this operation was interupted and you would like to continue from the last checkpoint.\")\n",
    "    while choice not in rightchoice:\n",
    "        choice = input(\"Wrong input. \\n Insert a number. Either 1 or 2\")\n",
    "    \n",
    "    if choice == '1':\n",
    "        nof = 0\n",
    "        ratings_wo_duplicates = ratings_new\n",
    "        count=0\n",
    "    else:\n",
    "        nof = int(input('Please insert the number of processed and stored items.'))\n",
    "        ratings_wo_duplicates=pd.read_csv(os.path.join(new_data_dir,'ratings_wo_duplicates.csv'), sep=';', names=r_cols, encoding='latin-1', low_memory=False )\n",
    "        count= nof\n",
    "    \n",
    "    # create a series with all the duplicates (including the first occurance) to iterate\n",
    "    temp=items[(items.duplicated(['book_title', 'book_author'],keep=False))][nof:]\n",
    "    \n",
    "    for t in tqdm.tqdm_notebook(temp['book_title']):\n",
    "        x = list( items[items['book_title']==t].isbn)\n",
    "        count+=1 \n",
    "        for i in range(1, len(x)):\n",
    "            #replace all entries in x list with x[0] (the isbn we kept in items_wo_duplicates)\n",
    "            ratings_wo_duplicates.loc[ratings_wo_duplicates.isbn==x[i],'isbn'] = x[0]\n",
    "\n",
    "        if count%2000==0:\n",
    "            ratings_wo_duplicates.to_csv(os.path.join(new_data_dir,'ratings_wo_duplicates.csv'),';', index=False)\n",
    "            print(count ,' duplicate items ratings processed and stored')\n",
    "            \n",
    "    ratings_wo_duplicates.to_csv(os.path.join(new_data_dir,'ratings_wo_duplicates.csv'),';', index=False)\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "ratings_wo_duplicates = ratings_wo_duplicates.loc[1:]\n",
    "ratings_wo_duplicates.reset_index(drop=True, inplace=True)\n",
    "ratings_wo_duplicates.rating = ratings_wo_duplicates.rating.astype(int)\n",
    "print('\\nAnd to make sure that the procedure was carried out smoothly,')\n",
    "print('No of duplicates in \\\"ratings_wo_duplicates\\\" :',ratings_wo_duplicates.isbn[ratings_wo_duplicates.isbn.isin(items[items.duplicated(['book_title', 'book_author'])].isbn)].count()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_expl = ratings_wo_duplicates[ratings_wo_duplicates.rating != 0]\n",
    "ratings_impl = ratings_wo_duplicates[ratings_wo_duplicates.rating == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id        isbn         rating\n",
      "count   383852      383852  383852.000000\n",
      "unique   68092      137646            NaN\n",
      "top      11676  0316666343            NaN\n",
      "freq      6943         707            NaN\n",
      "mean       NaN         NaN       7.626710\n",
      "std        NaN         NaN       1.841331\n",
      "min        NaN         NaN       1.000000\n",
      "25%        NaN         NaN       7.000000\n",
      "50%        NaN         NaN       8.000000\n",
      "75%        NaN         NaN       9.000000\n",
      "max        NaN         NaN      10.000000 \n",
      "\n",
      "       user_id        isbn    rating\n",
      "count   647322      647322  647322.0\n",
      "unique   52451      184258       NaN\n",
      "top     198711  0971880107       NaN\n",
      "freq      6439        1921       NaN\n",
      "mean       NaN         NaN       0.0\n",
      "std        NaN         NaN       0.0\n",
      "min        NaN         NaN       0.0\n",
      "25%        NaN         NaN       0.0\n",
      "50%        NaN         NaN       0.0\n",
      "75%        NaN         NaN       0.0\n",
      "max        NaN         NaN       0.0\n"
     ]
    }
   ],
   "source": [
    "print(ratings_expl.describe(include=[object,int]),'\\n')\n",
    "print(ratings_impl.describe(include=[object,int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_w_ex_ratings = users_new[users_new.user_id.isin(ratings_expl.user_id)]\n",
    "users_w_im_ratings = users_new[users_new.user_id.isin(ratings_impl.user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_w_ratings = items_wo_duplicates[items_wo_duplicates.isbn.isin(ratings_wo_duplicates.isbn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!!\n"
     ]
    }
   ],
   "source": [
    "users_new.to_csv(os.path.join(new_data_dir,'users_new.csv'),';', index=False)\n",
    "users_w_ex_ratings.to_csv(os.path.join(new_data_dir,'users_w_ex_ratings.csv'),';', index=False)\n",
    "users_w_im_ratings.to_csv(os.path.join(new_data_dir,'users_w_im_ratings.csv'),';', index=False)\n",
    "items_wo_duplicates.to_csv(os.path.join(new_data_dir,'items_wo_duplicates.csv'),';', index=False)\n",
    "ratings_wo_duplicates.to_csv(os.path.join(new_data_dir,'ratings_wo_duplicates.csv'),';', index=False)\n",
    "ratings_expl.to_csv(os.path.join(new_data_dir,'ratings_expl.csv'),';', index=False)\n",
    "ratings_impl.to_csv(os.path.join(new_data_dir,'ratings_impl.csv'),';', index=False)\n",
    "print(\"DONE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
